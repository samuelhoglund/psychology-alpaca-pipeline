{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the pipeline to fine-tune a basic LLaMA model through SFT and RLHF/RLAIF\n",
        "- This notebook includes both a supervised finetuning step (finetuning base model and reward model) and a proximal policy optimization step (optimizing finetuned model through proximal policy optimization with reward model)\n",
        "\n",
        "- The notebook was written by Samuel HÃ¶glund and Josef Khedri for their bachelor's thesis on comparing RLHF and RLAIF\n",
        "  - For more information about our work, head over to https://huggingface.co/KTH/psychology-alpaca\n",
        "\n",
        "- The following code uses a forked GitHub repository originally created by user https://github.com/jackaduma\n",
        "\n"
      ],
      "metadata": {
        "id": "3Uj7gshPmNkC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4vW0VgCICzd"
      },
      "source": [
        "## Clone repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvluEVB2HpLY"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/jkhedri/Alpaca-LoRA-RLHF-PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zJTac0GQlw5"
      },
      "outputs": [],
      "source": [
        "%cd Alpaca-LoRA-RLHF-PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi5yPdwXQyxv"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQd-M-fzIBMH"
      },
      "source": [
        "## Install requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax4WRqLKH6wS"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJPTQ-iFS9Et"
      },
      "source": [
        "## Evaluate needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDv5UzNpRoOG"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iienEBWEQ_q4"
      },
      "source": [
        "## Insert huggingface token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbMCogTrQ_FG"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA4jKlsT1Vs5"
      },
      "source": [
        "## Supervised fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetune base model"
      ],
      "metadata": {
        "id": "kb3uOVw0pquX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTGv3J3G1YsM"
      },
      "outputs": [],
      "source": [
        "!python supervised_finetune.py --base_model 'decapoda-research/llama-7b-hf' --data_path 'samhog/psychology-6k' --output_dir 'psychology-llama' --num_epochs 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03w0GOsNInej"
      },
      "source": [
        "## Finetune reward model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8cgAuKuIpw1"
      },
      "outputs": [],
      "source": [
        "!python train_reward_model.py --model_name 'decapoda-research/llama-7b-hf' --gradient_accumulation_steps 32 --per_device_train_batch_size 1 --train_subset 1750 --eval_subset 250 --local_rank 0 --bf16 True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xC6B3L2z2P9"
      },
      "source": [
        "## Merge adapters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7wn_nio42hU"
      },
      "source": [
        "### Peft 0.2.0 needed for this script to work. Make sure to change the version by running this code before running the script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuOJ-U-73H_7"
      },
      "outputs": [],
      "source": [
        "!pip uninstall peft\n",
        "!pip install peft==0.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "666TXC6Cz4cZ"
      },
      "outputs": [],
      "source": [
        "!python merge_peft_adapter.py --model_name \"samhog/psychology-llama\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhv_sgGF8Uy9"
      },
      "source": [
        "### TRL needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKi-o0Is5rVA"
      },
      "outputs": [],
      "source": [
        "#!pip install trl\n",
        "!git clone https://github.com/lvwerra/trl.git\n",
        "%cd trl/\n",
        "!pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LmSNufZ5DJs"
      },
      "source": [
        "## PPO plug & chug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyYUvpAj0WrC"
      },
      "source": [
        "if you have installed peft 0.2.0, get it back to current version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoEG6b-50IDj"
      },
      "outputs": [],
      "source": [
        "!pip uninstall peft\n",
        "!pip install git+https://github.com/huggingface/peft.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMWt4A8W79pc"
      },
      "outputs": [],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Muwq2-JE1muJ"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv3EtvkrOO6f"
      },
      "source": [
        "## Reminder to change name of hf repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jdkzz2Bb5BZO"
      },
      "outputs": [],
      "source": [
        "!python tuning_lm_with_rl.py --model_name 'samhog/psychology-llama-merged' --reward_model_name 'samhog/RLAIF-psychology-alpaca-rm-merged' --log_with='wandb' --adafactor False --tokenizer_name 'decapoda-research/llama-7b-hf' --save_freq 100 --output_max_length 128 --batch_size 8 --gradient_accumulation_steps 8 --batched_gen True --ppo_epochs 1 --seed 0 --learning_rate 1.4e-5 --early_stopping True --output_dir './checkpoints/tuning_llama_rl'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}